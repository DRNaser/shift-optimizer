# WEEKLY-AUDIT: Enterprise Audit Report Generation
# Runs on: Every Sunday at 00:00 UTC
# Purpose: Generate audit-ready evidence packs for all tenants
#
# Skills covered: 113
# - 113: Enterprise Audit Report Generator (orchestrates 101, 103, 104, 106, 111, 112)
#
# Outputs:
# - ENTERPRISE_PROOF_PACK_<date>.zip per tenant
# - AUDIT_SUMMARY.md (CISO-readable)
# - COMPLIANCE_MATRIX.md (GDPR/SOC2/ISO27001)
# - EVIDENCE_HASHES.json (tamper-proof chain)

name: Weekly Audit Report

on:
  schedule:
    - cron: '0 0 * * 0'  # Every Sunday at 00:00 UTC
  workflow_dispatch:
    inputs:
      tenant:
        description: 'Specific tenant code (leave empty for all)'
        required: false
        default: ''
      compliance_frameworks:
        description: 'Compliance frameworks (comma-separated)'
        required: false
        default: 'GDPR,SOC2,ISO27001'

concurrency:
  group: weekly-audit
  cancel-in-progress: false  # Never cancel audit runs

env:
  AUDIT_RETENTION_DAYS: 90
  AUDIT_STORAGE_PATH: audit_reports

jobs:
  # ============================================
  # PREPARE AUDIT ENVIRONMENT
  # ============================================
  prepare:
    name: üìã Prepare Audit Environment
    runs-on: ubuntu-latest
    outputs:
      date: ${{ steps.date.outputs.date }}
      tenants: ${{ steps.tenants.outputs.list }}

    steps:
      - uses: actions/checkout@v4

      - name: Get audit date
        id: date
        run: echo "date=$(date +%Y-%m-%d)" >> $GITHUB_OUTPUT

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r backend_py/requirements.txt

      - name: Get tenant list
        id: tenants
        run: |
          if [ -n "${{ github.event.inputs.tenant }}" ]; then
            echo "list=[\"${{ github.event.inputs.tenant }}\"]" >> $GITHUB_OUTPUT
          else
            # Get all active tenants from config or database
            python -c "
          import json
          # For now, return a placeholder list
          # In production, this would query the database
          tenants = ['default']
          print(f'list={json.dumps(tenants)}')
          " >> $GITHUB_OUTPUT
          fi

  # ============================================
  # COLLECT EVIDENCE (Skills 101, 103, 104, 106, 111)
  # ============================================
  collect-evidence:
    name: üîç Collect Evidence
    runs-on: ubuntu-latest
    needs: prepare
    timeout-minutes: 60

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_DB: solvereign_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r backend_py/requirements.txt
          pip install ortools==9.11.4210

      - name: Apply migrations
        run: |
          for f in backend_py/db/migrations/*.sql; do
            psql $DATABASE_URL < "$f" || true
          done
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/solvereign_test

      - name: Create evidence directory
        run: mkdir -p evidence

      - name: üîê Run RLS Leak Harness (101)
        run: |
          python -m backend_py.skills.rls_leak_harness \
            --tenants 5 \
            --operations 100 \
            --output evidence/rls_harness.json \
            || echo '{"passed": false, "error": "Not implemented"}' > evidence/rls_harness.json
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/solvereign_test

      - name: üéØ Run Determinism Proof (103)
        run: |
          python -m backend_py.skills.determinism_proof \
            --mode quick \
            --runs 3 \
            --output evidence/determinism.json \
            || echo '{"passed": false, "error": "Not implemented"}' > evidence/determinism.json
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/solvereign_test

      - name: üõ°Ô∏è Run BFF Boundary Check (104)
        run: |
          python -m backend_py.skills.bff_boundary \
            --output evidence/bff_boundary.json \
            || echo '{"passed": false, "error": "Not implemented"}' > evidence/bff_boundary.json

      - name: üìú Run Migration Contract Check (106)
        run: |
          python -m backend_py.skills.migration_contract \
            --output evidence/migration_contract.json \
            || echo '{"passed": false, "error": "Not implemented"}' > evidence/migration_contract.json

      - name: üì∏ Generate Knowledge Snapshot (111)
        run: |
          python -m backend_py.skills.knowledge_snapshot generate \
            --output evidence/knowledge_snapshot.json \
            || echo '{"error": "Not implemented"}' > evidence/knowledge_snapshot.json

      - name: Upload evidence artifacts
        uses: actions/upload-artifact@v4
        with:
          name: evidence-${{ needs.prepare.outputs.date }}
          path: evidence/
          retention-days: ${{ env.AUDIT_RETENTION_DAYS }}

  # ============================================
  # GENERATE AUDIT REPORT (Skill 113)
  # ============================================
  generate-report:
    name: üìä Generate Audit Report
    runs-on: ubuntu-latest
    needs: [prepare, collect-evidence]
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r backend_py/requirements.txt

      - name: Download evidence
        uses: actions/download-artifact@v4
        with:
          name: evidence-${{ needs.prepare.outputs.date }}
          path: evidence/

      - name: Create report directory
        run: mkdir -p ${{ env.AUDIT_STORAGE_PATH }}

      - name: üìä Generate Enterprise Audit Report (113)
        run: |
          python -m backend_py.skills.audit_report generate \
            --evidence-dir evidence/ \
            --frameworks "${{ github.event.inputs.compliance_frameworks || 'GDPR,SOC2,ISO27001' }}" \
            --output-dir ${{ env.AUDIT_STORAGE_PATH }} \
            || {
              echo "Audit report generator not yet implemented - creating placeholder"
              echo "# AUDIT REPORT PLACEHOLDER" > ${{ env.AUDIT_STORAGE_PATH }}/AUDIT_SUMMARY.md
              echo "Generated: $(date)" >> ${{ env.AUDIT_STORAGE_PATH }}/AUDIT_SUMMARY.md
              echo "Status: Skill 113 not yet implemented" >> ${{ env.AUDIT_STORAGE_PATH }}/AUDIT_SUMMARY.md
            }

      - name: Generate compliance matrix
        run: |
          if [ ! -f "${{ env.AUDIT_STORAGE_PATH }}/COMPLIANCE_MATRIX.md" ]; then
            cat > ${{ env.AUDIT_STORAGE_PATH }}/COMPLIANCE_MATRIX.md << 'EOF'
          # Compliance Matrix

          | Framework | Control | Evidence | Status |
          |-----------|---------|----------|--------|
          | GDPR | Data Isolation | RLS Harness | PENDING |
          | SOC2 | Access Control | BFF Boundary | PENDING |
          | ISO27001 | Change Management | Migration Contract | PENDING |

          *Generated: ${{ needs.prepare.outputs.date }}*
          EOF
          fi

      - name: Generate evidence hash chain (DETERMINISTIC)
        run: |
          # Create hash chain for tamper detection
          # DETERMINISM NOTE: master_hash is computed from SORTED evidence hashes only
          # The generated_at is metadata only - NOT part of master_hash
          # If same evidence files => same master_hash (deterministic)
          python << 'EOF'
          import hashlib
          import json
          import os
          from datetime import datetime

          evidence_dir = "evidence"
          hashes = {}

          # Hash each evidence file (deterministic per file)
          for f in sorted(os.listdir(evidence_dir)):  # SORT for determinism
              if f.endswith('.json'):
                  with open(os.path.join(evidence_dir, f), 'rb') as file:
                      hashes[f] = hashlib.sha256(file.read()).hexdigest()

          # Compute master hash (DETERMINISTIC: sorted + combined)
          combined = ''.join(sorted(hashes.values()))
          master_hash = hashlib.sha256(combined.encode()).hexdigest()

          result = {
              # Metadata (not part of hash chain)
              "generated_at": datetime.utcnow().isoformat() + "Z",
              # Deterministic content
              "evidence_hashes": hashes,
              "master_hash": master_hash,  # THIS IS DETERMINISTIC
              "hash_algorithm": "SHA256",
              # Determinism proof
              "determinism_note": "master_hash is computed from sorted(evidence_hashes.values()) only - same inputs = same hash"
          }

          with open("${{ env.AUDIT_STORAGE_PATH }}/EVIDENCE_HASHES.json", 'w') as f:
              json.dump(result, f, indent=2, sort_keys=True)  # sort_keys for determinism

          print(f"Master hash: {master_hash}")
          print(f"Evidence files: {len(hashes)}")
          EOF

      - name: Create audit pack ZIP
        run: |
          cd ${{ env.AUDIT_STORAGE_PATH }}
          zip -r ../ENTERPRISE_PROOF_PACK_${{ needs.prepare.outputs.date }}.zip .
          cd ..
          mv ENTERPRISE_PROOF_PACK_${{ needs.prepare.outputs.date }}.zip ${{ env.AUDIT_STORAGE_PATH }}/

      - name: Upload audit report
        uses: actions/upload-artifact@v4
        with:
          name: audit-report-${{ needs.prepare.outputs.date }}
          path: |
            ${{ env.AUDIT_STORAGE_PATH }}/AUDIT_SUMMARY.md
            ${{ env.AUDIT_STORAGE_PATH }}/COMPLIANCE_MATRIX.md
            ${{ env.AUDIT_STORAGE_PATH }}/EVIDENCE_HASHES.json
            ${{ env.AUDIT_STORAGE_PATH }}/ENTERPRISE_PROOF_PACK_${{ needs.prepare.outputs.date }}.zip
          retention-days: ${{ env.AUDIT_RETENTION_DAYS }}

  # ============================================
  # REDACTION LEAK TEST (Skill 113) - CRITICAL
  # Verifies customer-safe output has ZERO sensitive data
  # ============================================
  redaction-leak-test:
    name: üîí Redaction Leak Test
    runs-on: ubuntu-latest
    needs: prepare
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üîí Run Redaction Leak Test (113)
        run: |
          python backend_py/skills/audit_report/tests/test_redaction_leak.py

      - name: Upload leak test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: redaction-leak-test-${{ needs.prepare.outputs.date }}
          path: redaction_test_*.json
          retention-days: ${{ env.AUDIT_RETENTION_DAYS }}

  # ============================================
  # VALIDATE ONBOARDING GATES (Skill 112)
  # ============================================
  validate-onboarding:
    name: ‚úÖ Validate Onboarding Gates
    runs-on: ubuntu-latest
    needs: [prepare, collect-evidence]
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_DB: solvereign_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r backend_py/requirements.txt
          pip install ortools==9.11.4210

      - name: Apply migrations
        run: |
          for f in backend_py/db/migrations/*.sql; do
            psql $DATABASE_URL < "$f" || true
          done
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/solvereign_test

      - name: ‚úÖ Validate Onboarding Gates (112)
        run: |
          python -m backend_py.skills.onboarding_contract validate \
            --all-gates \
            --output onboarding_validation.json \
            || echo '{"all_passed": false, "error": "Not implemented"}' > onboarding_validation.json
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/solvereign_test

      - name: Check gate status
        run: |
          ALL_PASSED=$(jq '.all_passed // false' onboarding_validation.json)
          if [ "$ALL_PASSED" != "true" ]; then
            echo "‚ö†Ô∏è Some onboarding gates did not pass"
            jq '.gates // {}' onboarding_validation.json
          else
            echo "‚úÖ All onboarding gates pass"
          fi

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        with:
          name: onboarding-validation-${{ needs.prepare.outputs.date }}
          path: onboarding_validation.json
          retention-days: ${{ env.AUDIT_RETENTION_DAYS }}

  # ============================================
  # SUMMARY
  # ============================================
  summary:
    name: üìã Weekly Audit Summary
    runs-on: ubuntu-latest
    needs: [prepare, collect-evidence, generate-report, redaction-leak-test, validate-onboarding]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "# üìã Weekly Audit Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** ${{ needs.prepare.outputs.date }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Evidence Collection" >> $GITHUB_STEP_SUMMARY
          echo "| Skill | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| RLS Harness (101) | ${{ needs.collect-evidence.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Determinism (103) | ${{ needs.collect-evidence.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| BFF Boundary (104) | ${{ needs.collect-evidence.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Migration Contract (106) | ${{ needs.collect-evidence.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Knowledge Snapshot (111) | ${{ needs.collect-evidence.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Report Generation" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Audit Report (113) | ${{ needs.generate-report.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Redaction Leak Test (113) | ${{ needs.redaction-leak-test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Onboarding Gates (112) | ${{ needs.validate-onboarding.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- ENTERPRISE_PROOF_PACK_${{ needs.prepare.outputs.date }}.zip" >> $GITHUB_STEP_SUMMARY
          echo "- AUDIT_SUMMARY.md" >> $GITHUB_STEP_SUMMARY
          echo "- COMPLIANCE_MATRIX.md" >> $GITHUB_STEP_SUMMARY
          echo "- EVIDENCE_HASHES.json" >> $GITHUB_STEP_SUMMARY

      - name: Check for failures
        run: |
          if [ "${{ needs.collect-evidence.result }}" == "failure" ]; then
            echo "‚ö†Ô∏è Evidence collection had failures"
          fi
          if [ "${{ needs.generate-report.result }}" == "failure" ]; then
            echo "‚ö†Ô∏è Report generation failed"
            exit 1
          fi
          if [ "${{ needs.redaction-leak-test.result }}" == "failure" ]; then
            echo "üö® CRITICAL: Redaction leak test FAILED!"
            echo "Customer-safe output contains sensitive data - blocking audit release"
            exit 1
          fi
          echo "‚úÖ Weekly audit completed (Skills: 101, 103, 104, 106, 111, 112, 113)"

      - name: Notify on failure
        if: failure()
        run: |
          echo "üö® Weekly audit failed - manual review required"
          # In production, this would send a notification (Slack, email, etc.)
